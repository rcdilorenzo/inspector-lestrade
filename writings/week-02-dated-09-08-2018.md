# [MSDS 686] Week 2 Eye Tracking Update (Sep 1, 2018)

<img alt="blurred faces with boxes" src="https://raw.githubusercontent.com/rcdilorenzo/msds-686-eye-tracking/master/visualizations/faces-blurred-grayscale.png" width="50%">

## Exploratory Data Analysis (EDA)

(Link: [https://github.com/rcdilorenzo/msds-686-eye-tracking/blob/master/eye-tracking-eda.ipynb](https://github.com/rcdilorenzo/msds-686-eye-tracking/blob/master/eye-tracking-eda.ipynb))

Using the [GazeCapture data](http://gazecapture.csail.mit.edu) collected by seven researchers across three universities, I have been primarily focused this week on the exploratory data analysis of the data set while concurrently exploring Deep Learning architectures (see resources below). This [data set](http://gazecapture.csail.mit.edu) includes +1,450 participants that comprise a database of camera snapshots of each participant gazing at a dot generated on the screen of their iOS device. Through the EDA, I was able to discover not only the 2.4 million frames but also that the iOS devices range from an iPhone 4s to an iPad Pro. In fact, I wrote a brief Medium.com article ([Visualization Quick Tip: Relative Heatmaps](https://medium.com/@rcdilorenzo/visualization-quick-tip-relative-heatmaps-86a52a0c5a0c)) that walks through the point visualization in the "Dot Info" of the notebook (linked above).

Likewise, I was able to discover the relative camera projection of the selected dot points. This will more than likely be the target of my final neural network. The goal is to eventually be able to directly take a webcam image and see where the person is looking on the mobile screen. However, after seeing more than several visuals of the Apple-provided detection regions of people's face and eyes, I may resort to using a non-realtime algorithm to detect the faces and thereby feed my neural network gaze prediction. 

Next week, I am going to have to do much more reading to understand object detection and try it out on some sample dataset. I expect I may have less visuals to show but hopefully a much better understanding of how to model things going forward.

## Completed Tasks
- Completed [EDA](https://github.com/rcdilorenzo/msds-686-eye-tracking/blob/master/eye-tracking-eda.ipynb) for GazeCapture
- Added [repository](https://github.com/rcdilorenzo/msds-686-eye-tracking) for all project results as well as [installation instructions](https://github.com/rcdilorenzo/msds-686-eye-tracking)
- Wrote brief article on progression of visualization that I found to be helpful: [Visualization Quick
 Tip: Relative Heatmaps, Medium.com](https://medium.com/@rcdilorenzo/visualization-quick-tip-relative-heatmaps-86a52a0c5a0c)
- Made progress on [MNIST experiment](https://github.com/rcdilorenzo/deep-learning-experiments/blob/master/step-01-mnist/Modeling.ipynb) (visualized with TensorBoard, start tweaking hyperparameters)
- Read in *Deep Learning in Python* (training from existing models, Convnets)
- Research/reading articles on object detection
    - [Real-time Object Detection with YOLO, YOLOv2 and now YOLOv3](https://medium.com/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088)
    - [Object detection with neural networks—a simple tutorial using keras](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491)
    - [Fashion-MNIST with tf.Keras](https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a)

## The Week Ahead
- Primary focus: reading and research
- Try using ResNet model as starting basis (see notes)
- Mostly focus on experimenting with object detection modeling (or other regression-based DNNs)
- If time permits, experiment with mapping from existing known features (face and eyes) to gaze prediction camera point.

## Notes

Because some of the Apple libraries were doing the detection on the fly and seem to be more than occassionally off (based on my visual inspection during EDA), I would like to try and improve the accuracy of the entire project by starting
 with a higher performant face (and eye) detection model. That way, I can start with better eye detection.

## Resources

- [Deep Learning in Python](https://www.datacamp.com/courses/deep-learning-in-python) - DataCamp course (finished last week)
- [Convolution Neural Networks for Image Processing](https://www.datacamp.com/courses/convolutional-neural-networks-for-image-processing) - DataCamp course (started and completed last week)
- [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by François Chollet - Excellent resource by the creator of keras
- [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard) - Fantastic visualization of neural network metrics


